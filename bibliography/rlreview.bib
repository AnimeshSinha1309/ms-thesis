% Introductions

@article{abbeel-rl-visual-motor-policy,
  title     = {End-to-end training of deep visuomotor policies},
  author    = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal   = {The Journal of Machine Learning Research},
  volume    = {17},
  number    = {1},
  pages     = {1334--1373},
  year      = {2016},
  publisher = {JMLR. org}
}

% Deep Q Networks

@inproceedings{actor-critic-a2c,
  title        = {Asynchronous methods for deep reinforcement learning},
  author       = {Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle    = {International conference on machine learning},
  pages        = {1928--1937},
  year         = {2016},
  organization = {PMLR}
}

@inproceedings{actor-critic-a3c,
  title        = {Asynchronous methods for deep reinforcement learning},
  author       = {Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle    = {International conference on machine learning},
  pages        = {1928--1937},
  year         = {2016},
  organization = {PMLR}
}

@article{actor-critic-gae,
  title   = {High-dimensional continuous control using generalized advantage estimation},
  author  = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal = {arXiv preprint arXiv:1506.02438},
  year    = {2015}
}

@article{atari-dqn,
  title   = {Playing atari with deep reinforcement learning},
  author  = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal = {arXiv preprint arXiv:1312.5602},
  year    = {2013}
}

% Policy gradients

@article{atari-dqn-human-level,
  title     = {Human-level control through deep reinforcement learning},
  author    = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal   = {nature},
  volume    = {518},
  number    = {7540},
  pages     = {529--533},
  year      = {2015},
  publisher = {Nature Publishing Group}
}

@article{ddpg,
  title   = {Continuous control with deep reinforcement learning},
  author  = {Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal = {arXiv preprint arXiv:1509.02971},
  year    = {2015}
}

@inproceedings{double-dqn,
  title     = {Deep reinforcement learning with double q-learning},
  author    = {Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle = {Proceedings of the AAAI conference on artificial intelligence},
  volume    = {30},
  year      = {2016}
}

% PPO and TRPO

@article{importance-sampling,
  title   = {On a connection between importance sampling and the likelihood ratio policy gradient},
  author  = {Jie, Tang and Abbeel, Pieter},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {23},
  pages   = {1000--1008},
  year    = {2010}
}

@article{mcts-alphago,
  author  = {Silver, David
             and Huang, Aja
             and Maddison, Chris J.
             and Guez, Arthur
             and Sifre, Laurent
             and van den Driessche, George
             and et al.},
  title   = {Mastering the game of Go with deep neural networks and tree search},
  journal = {Nature},
  year    = {2016},
  month   = {Jan},
  day     = {01},
  volume  = {529},
  number  = {7587},
  pages   = {484-489},
  issn    = {1476-4687},
  doi     = {10.1038/nature16961}
}

@article{mcts-alphazero,
  author        = {David Silver and
                   Thomas Hubert and
                   Julian Schrittwieser and
                   Ioannis Antonoglou and
                   Matthew Lai and
                   Arthur Guez and
                   Marc Lanctot and
                   Laurent Sifre and
                   Dharshan Kumaran and
                   Thore Graepel and
                   Timothy P. Lillicrap and
                   Karen Simonyan and
                   Demis Hassabis},
  title         = {{Mastering Chess and Shogi by Self-Play with a General Reinforcement
                   Learning Algorithm}},
  journal       = {arXiv e-prints},
  year          = 2017,
  month         = aug,
  archiveprefix = {arXiv},
  eprint        = {1712.01815},
  primaryclass  = {CoRR}
}

@article{mcts-assymetric,
  author        = {{Moerland}, Thomas M. and {Broekens}, Joost and {Plaat}, Aske and {Jonker}, Catholijn M.},
  title         = {{Monte Carlo Tree Search for Asymmetric Trees}},
  journal       = {arXiv e-prints},
  keywords      = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  year          = 2018,
  month         = may,
  archiveprefix = {arXiv},
  eprint        = {1805.09218},
  primaryclass  = {stat.ML}
}

% DDPG and SAC

@inproceedings{mcts-bandit-1,
  title     = {Bandit Based Monte-Carlo Planning},
  author    = {L. Kocsis and Csaba Szepesvari},
  booktitle = {ECML},
  year      = {2006}
}

@article{mcts-bandit-2,
  title   = {From Bandits to Monte-Carlo Tree Search: The Optimistic Principle Applied to Optimization and Planning},
  author  = {R. Munos},
  journal = {Found. Trends Mach. Learn.},
  year    = {2014},
  volume  = {7},
  pages   = {1-129}
}

% Actor Critic

@inproceedings{mcts-nets,
  title        = {Learning to search with mctsnets},
  author       = {Guez, Arthur and Weber, Th{\'e}ophane and Antonoglou, Ioannis and Simonyan, Karen and Vinyals, Oriol and Wierstra, Daan and Munos, R{\'e}mi and Silver, David},
  booktitle    = {International conference on machine learning},
  pages        = {1822--1831},
  year         = {2018},
  organization = {PMLR}
}

@article{mcts-survey,
  author  = {C. B. {Browne} and E. {Powley} and D. {Whitehouse} and S. M. {Lucas} and P. I. {Cowling} and P. {Rohlfshagen} and S. {Tavener} and D. {Perez} and S. {Samothrakis} and S. {Colton}},
  journal = {IEEE Transactions on Computational Intelligence and AI in Games},
  title   = {A Survey of Monte Carlo Tree Search Methods},
  year    = {2012},
  volume  = {4},
  number  = {1},
  pages   = {1-43},
  doi     = {10.1109/TCIAIG.2012.2186810}
}

@inproceedings{mcts-uct,
  title        = {Bandit based monte-carlo planning},
  author       = {Kocsis, Levente and Szepesv{\'a}ri, Csaba},
  booktitle    = {European conference on machine learning},
  pages        = {282--293},
  year         = {2006},
  organization = {Springer}
}

% MCTS

@article{policy-grad-infinite-horizon-gpomdp,
  title   = {Infinite-horizon policy-gradient estimation},
  author  = {Baxter, Jonathan and Bartlett, Peter L},
  journal = {Journal of Artificial Intelligence Research},
  volume  = {15},
  pages   = {319--350},
  year    = {2001}
}

@inproceedings{policy-grad-theorem,
  title     = {Policy gradient methods for reinforcement learning with function approximation},
  author    = {Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle = {Advances in neural information processing systems},
  pages     = {1057--1063},
  year      = {2000}
}

@article{policy-reinforce,
  title     = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author    = {Williams, Ronald J},
  journal   = {Machine learning},
  volume    = {8},
  number    = {3},
  pages     = {229--256},
  year      = {1992},
  publisher = {Springer}
}

@article{ppo,
  title   = {Proximal policy optimization algorithms},
  author  = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal = {arXiv preprint arXiv:1707.06347},
  year    = {2017}
}

@article{ppo-rubics-openai,
  title   = {Solving rubik's cube with a robot hand},
  author  = {Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and others},
  journal = {arXiv preprint arXiv:1910.07113},
  year    = {2019}
}

@inproceedings{rainbow-dqn,
  title     = {Rainbow: Combining improvements in deep reinforcement learning},
  author    = {Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle = {Thirty-second AAAI conference on artificial intelligence},
  year      = {2018}
}

@article{rl-intro-sutton-barto,
  title     = {Reinforcement learning: an introduction, by Sutton, RS and Barto, AG},
  author    = {Montague, P Read},
  journal   = {Trends in cognitive sciences},
  volume    = {3},
  number    = {9},
  pages     = {360},
  year      = {1999},
  publisher = {Elsevier}
}

@inproceedings{sac,
  title        = {Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author       = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle    = {International conference on machine learning},
  pages        = {1861--1870},
  year         = {2018},
  organization = {PMLR}
}
% Others

@inproceedings{trpo,
  title        = {Trust region policy optimization},
  author       = {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle    = {International conference on machine learning},
  pages        = {1889--1897},
  year         = {2015},
  organization = {PMLR}
}